{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information value between 0.3 to 0.5 has strong predictive power\n"
     ]
    }
   ],
   "source": [
    "# 1) How can we use Information Value for feature selection?\n",
    "# None of the options are correct\n",
    "# Information value between 0.3 to 0.5 has strong predictive power\n",
    "# Information value between 0 to 0.02 has highest predictive power\n",
    "# Information value between 0.01 to 0.03 has very strong predictive power\n",
    "\n",
    "print('Information value between 0.3 to 0.5 has strong predictive power')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It has insignificant impact on the response variable\n"
     ]
    }
   ],
   "source": [
    "# 2) If the information value for a feature is 0.01, what inferences can be made for the feature?\n",
    "# It has very strong impact on the response variable\n",
    "# It has insignificant impact on the response variable\n",
    "# It has a high predictive power\n",
    "# It has a moderate impact on the response variable\n",
    "\n",
    "print(\"It has insignificant impact on the response variable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measures the strength of correlation between the independent variables\n"
     ]
    }
   ],
   "source": [
    "# 3) What is the objective of VIF in feature selection?\n",
    "# Measures the strength of correlation between independent and dependent variables.\n",
    "# Measures the strength of correlation between the independent variables\n",
    "# Measures the strength of correlation between dependent variables\n",
    "# None of the options are correct\n",
    "\n",
    "print('Measures the strength of correlation between the independent variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Variables with VIF less than 5 are highly correlated\n"
     ]
    }
   ],
   "source": [
    "# 4) How do you select features using VIF?\n",
    "# Variables with VIF more than 5 are moderately correlated\n",
    "# Variables with VIF less than 5 are highly correlated\n",
    "# Variables with VIF less than 5 are moderately correlated\n",
    "# None of the options are correct\n",
    "\n",
    "print(\"# Variables with VIF less than 5 are highly correlated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EigenValues analysis for feature selection\n"
     ]
    }
   ],
   "source": [
    "# 5) How can you use PCA for feature selection?\n",
    "# PCA cannot be used for feature selection\n",
    "# EigenValues analysis for feature selection\n",
    "# None of the Options are correct\n",
    "# Features are selected based on Sample Means\n",
    "\n",
    "print('EigenValues analysis for feature selection')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA is Unsupervised\n"
     ]
    }
   ],
   "source": [
    "# 6) Is PCA unsupervised or supervised?\n",
    "# PCA is Unsupervised\n",
    "# PCA is Supervised\n",
    "\n",
    "print(\"PCA is Unsupervised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduces the dimensionality of the data that best explains the data\n"
     ]
    }
   ],
   "source": [
    "# 7) How can you use LDA for feature selection?\n",
    "# None of the options are correct\n",
    "# Values between 15-20 are selected for further analysis\n",
    "# Reduces the dimensionality of the data that best explains the data\n",
    "# Cannot be used for feature selection\n",
    "\n",
    "print(\"Reduces the dimensionality of the data that best explains the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square is used for feature selection for categorical data\n"
     ]
    }
   ],
   "source": [
    "# 8) How can you use chi-square value for feature selection?\n",
    "# Chi-Square cannot be used for feature selection\n",
    "# None of the options are correct\n",
    "# Chi-Square is used for feature selection for continuous data\n",
    "# Chi-Square is used for feature selection for categorical data\n",
    "\n",
    "print(\"Chi-Square is used for feature selection for categorical data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate chi-square value for features and select highest scores\n"
     ]
    }
   ],
   "source": [
    "# 9) How do you select features using chi-square value?\n",
    "# Calculate chi-square value for features and select highest scores\n",
    "# None of the options are correct\n",
    "# Chi-Square cannot be used for feature selection\n",
    "# Calculate chi-square value for features and select lowest scores\n",
    "\n",
    "print(\"Calculate chi-square value for features and select highest scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IF THE TARGET HAS TWO CLASSES, NUMBER OF COMPONENTS WILL BE 1\n"
     ]
    }
   ],
   "source": [
    "# 10) How do you decide the number of components for LDA?\n",
    "# If the target has 10 classes, number of components will be 2\n",
    "# If the target has two classes, number of components will be 1\n",
    "# If the target is more than 10, number of components will be 5\n",
    "# None of the options are correct\n",
    "\n",
    "print(\"IF THE TARGET HAS TWO CLASSES, NUMBER OF COMPONENTS WILL BE 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All options are correct\n"
     ]
    }
   ],
   "source": [
    "# 11) What are log odds in logistic regression?\n",
    "# Log odds are given by logit function in logistic regression\n",
    "# Logarithm of Odds\n",
    "# All options are correct\n",
    "# Log odds creates a symmetry in likelihood of events\n",
    "\n",
    "print(\"All options are correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selects the model parameters that maximizes likelihood function\n"
     ]
    }
   ],
   "source": [
    "# 12) What is the maximum likelihood estimation used for?\n",
    "# Is a method to estimate hyperparameters in logistic regression\n",
    "# None of the options are correct\n",
    "# Selects the model parameters that minimizes likelihood function\n",
    "# Selects the model parameters that maximizes likelihood function\n",
    "\n",
    "print(\"Selects the model parameters that maximizes likelihood function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# 13) In logistic regression, for binary classification - the probability of less than 0.5 will predict?\n",
    "# 0\n",
    "# 1\n",
    "\n",
    "print(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL OPTIONS ARE CORRECT\n"
     ]
    }
   ],
   "source": [
    "# 14) Why do we prune the decision tree?\n",
    "# To improve the accuracy of the decision tree\n",
    "# To reduce the complexity of the decision tree\n",
    "# To reduce the size of the decision tree\n",
    "# All options are correct\n",
    "\n",
    "print(\"ALL OPTIONS ARE CORRECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL OPTIONS ARE CORRECT\n"
     ]
    }
   ],
   "source": [
    "# 15) What is gini index?\n",
    "# All options are correct\n",
    "# Gini index measures the entropy of values in the dataset\n",
    "# Gini index decreases entropy from the root nodes to the lead nodes\n",
    "# Gini index measures the randomness in the values of the dataset\n",
    "\n",
    "print(\"ALL OPTIONS ARE CORRECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between entropy of parent node and average entropy of child nodes\n"
     ]
    }
   ],
   "source": [
    "# 16) How do we measure the information gain for a decision tree?\n",
    "# IV value for features\n",
    "# Chi-Square value for features\n",
    "# None of the options are correct\n",
    "# Difference between entropy of parent node and average entropy of child nodes\n",
    "\n",
    "print(\"Difference between entropy of parent node and average entropy of child nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE\n"
     ]
    }
   ],
   "source": [
    "# 17) Random Forest algorithm can be used for both continuous and categorical variables?\n",
    "# FALSE\n",
    "# TRUE\n",
    "\n",
    "print(\"TRUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It uses random subsets of data to create many trees\n"
     ]
    }
   ],
   "source": [
    "# 18) Why is random forest called random?\n",
    "# All of the options are correct\n",
    "# It uses random subsets of data to create many trees\n",
    "# It uses binomial optimization techniques\n",
    "# It uses stratified sampling\n",
    "\n",
    "print(\"It uses random subsets of data to create many trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOTH 1 AND 2\n"
     ]
    }
   ],
   "source": [
    "# 19) How does the Random Forest model handle missing values?\n",
    "# Multiple Imputation by chained equation\n",
    "# Both 1 and 2\n",
    "# None of the options are correct\n",
    "# Missing Forest Technique\n",
    "\n",
    "print(\"BOTH 1 AND 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All options are correct\n"
     ]
    }
   ],
   "source": [
    "# 20) How can you improve the Random Forest model’s performance in terms of accuracy?\n",
    "# Feature Selection using Feature Importance\n",
    "# Reducing Features\n",
    "# Hyperparameter Tuning\n",
    "# All options are correct\n",
    "\n",
    "print(\"All options are correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both 1 and 2\n"
     ]
    }
   ],
   "source": [
    "# 21) How is the error calculated in a linear regression model?\n",
    "# Mean Squared Error\n",
    "# Mean Absolute Error\n",
    "# None of the options are correct\n",
    "# Both 1 and 2\n",
    "\n",
    "print(\"Both 1 and 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the model performs better on training set rather than test set, the model is likely to be overfitted\n"
     ]
    }
   ],
   "source": [
    "# 22) How to detect overfitting in a linear regression model?\n",
    "# If the model performs better on test set rather than training set, it is likely to be overfitted\n",
    "# If the model performs better on training set rather than test set, the model is likely to be overfitted\n",
    "# None of the options are correct\n",
    "# if accuracy is less than 0.5\n",
    "\n",
    "print(\"If the model performs better on training set rather than test set, the model is likely to be overfitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE identifies the larger errors to a great degree compared to MAE\n"
     ]
    }
   ],
   "source": [
    "# 23) How does mean squared error and mean absolute error differ?\n",
    "# MSE is better than MAE in calculating the loss\n",
    "# None of the options are correct\n",
    "# MSE identifies the larger errors to a great degree compared to MAE\n",
    "# MSE is more accurate than MAE in terms of accuracy\n",
    "\n",
    "print(\"MSE identifies the larger errors to a great degree compared to MAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both 1 and 3 are Correct\n"
     ]
    }
   ],
   "source": [
    "# 24) How does gradient descent work in linear regression?\n",
    "# Gradient Descent minimizes the cost function\n",
    "# None of the options are correct\n",
    "# Both 1 and 3 are Correct\n",
    "# Gradient Descent maximizes the cost function\n",
    "# Both 1 and 2 are Correct\n",
    "# Gradient Descent reduces the error between predicted and actual values\n",
    "\n",
    "print(\"Both 1 and 3 are Correct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis testing is used to validate the significance of beta coefficients\n"
     ]
    }
   ],
   "source": [
    "# 25) How does hypothesis testing work in linear regression?\n",
    "# Hypothesis testing is used to calculate the error in predictions\n",
    "# Hypothesis testing is used to predict outcomes\n",
    "# Hypothesis testing is used to validate the significance of beta coefficients\n",
    "# None of the options are correct\n",
    "\n",
    "print(\"Hypothesis testing is used to validate the significance of beta coefficients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating if the person has parkinson’s or not\n"
     ]
    }
   ],
   "source": [
    "# 26) Which among the following is not a time series?\n",
    "# Estimating the average temperature of a city for the next week\n",
    "# Estimating if the person has parkinson’s or not\n",
    "# None of the options\n",
    "# Estimating the revenue for the next quarter\n",
    "\n",
    "print(\"Estimating if the person has parkinson’s or not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both 1 and 2\n"
     ]
    }
   ],
   "source": [
    "# 27) Why do we check the stationarity of a time series?\n",
    "# None of the options are correct\n",
    "# If the time series is non-stationary, the forecasting will be flawed\n",
    "# Both 1 and 2\n",
    "# Stationary time series means the autocorrelation, variance and mean do not change overtime\n",
    "\n",
    "print(\"Both 1 and 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACF And PACF Plots\n"
     ]
    }
   ],
   "source": [
    "# 28) How do you evaluate the ARIMA order for a time series?\n",
    "# ADFuller Test\n",
    "# ACF And PACF Plots\n",
    "# None of the options are correct\n",
    "# Seasonal Decomposition\n",
    "\n",
    "print(\"ACF And PACF Plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fourier Transform\n"
     ]
    }
   ],
   "source": [
    "# 29) How do you remove noise from the time series?\n",
    "# Seasonal Decomposition\n",
    "# Fourier Transform\n",
    "# None of the options are correct\n",
    "# ADFuller Test\n",
    "\n",
    "print(\"Fourier Transform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACF and PACF of the seasonal component of the time series\n"
     ]
    }
   ],
   "source": [
    "# 30) How do you evaluate seasonal order in SARIMA forecasting?\n",
    "# ACF and PACF plots of the time series\n",
    "# None of the above\n",
    "# ACF and PACF of the seasonal component of the time series\n",
    "# ADFuller Test\n",
    "\n",
    "print(\"ACF and PACF of the seasonal component of the time series\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measure of dispersion between values of two clusters\n"
     ]
    }
   ],
   "source": [
    "# 31) What is inter-cluster variance?\n",
    "# Measure of spread between values of two clusters\n",
    "# Measure of kurtosis between values of two clusters\n",
    "# None of the above\n",
    "# Measure of dispersion between values of two clusters\n",
    "\n",
    "print(\"Measure of dispersion between values of two clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEASURE OF DISPERSION BETWEEN THE VALUES OF THE SAME CLUSTER\n"
     ]
    }
   ],
   "source": [
    "# 32) What is intra-cluster variance?\n",
    "# None of the above\n",
    "# Measure of spread between the values of the same cluster\n",
    "# Measure of kurtosis between the values of the same cluster\n",
    "# Measure of dispersion between the values of the same cluster\n",
    "\n",
    "print(\"MEASURE OF DISPERSION BETWEEN THE VALUES OF THE SAME CLUSTER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbow Method & Silhouette Method\n"
     ]
    }
   ],
   "source": [
    "# 33) How do you decide k-value for K-Means Clustering?\n",
    "# Elbow Method & Silhouette Method\n",
    "# Elbow Method\n",
    "# None of the Options are Correct\n",
    "# Silhouette Method\n",
    "\n",
    "print(\"Elbow Method & Silhouette Method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters are of the same size\n"
     ]
    }
   ],
   "source": [
    "# 34) What is an assumption taken for K-Means Clustering?\n",
    "# No Clusters\n",
    "# Clusters are cylindrical\n",
    "# None of the Options are Correct\n",
    "# Clusters are of the same size\n",
    "\n",
    "print(\"Clusters are of the same size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient\n"
     ]
    }
   ],
   "source": [
    "# 35) How do you evaluate the K-Means Clustering model?\n",
    "# Classification Report\n",
    "# Silhouette Coefficient\n",
    "# Mean Squared Error\n",
    "# Mean Absolute Error\n",
    "\n",
    "print(\"Silhouette Coefficient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both 1 and 2\n"
     ]
    }
   ],
   "source": [
    "# 36) What is hierarchical clustering?\n",
    "# None of the above\n",
    "# There is no need to specify number of clusters\n",
    "# Both 1 and 2\n",
    "# Uses dendrogram to create clusters\n",
    "\n",
    "print(\"Both 1 and 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additive Hierarchical Clustering\n"
     ]
    }
   ],
   "source": [
    "# 37) What is not a type of hierarchical clustering amongst the following?\n",
    "# Divisive Hierarchical Clustering\n",
    "# Agglomerative Hierarchical Clustering\n",
    "# None of the above\n",
    "# Additive Hierarchical Clustering\n",
    "\n",
    "print(\"Additive Hierarchical Clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Distance between clusters in hierarchical clustering\n"
     ]
    }
   ],
   "source": [
    "# 38) What is the group average method?\n",
    "# Calculating within cluster variance in hierarchical clustering\n",
    "# Calculating Distance between clusters in hierarchical clustering\n",
    "# None of the above\n",
    "# Calculating Distance within cluster from centroid in hierarchical clustering\n",
    "\n",
    "print(\"Calculating Distance between clusters in hierarchical clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shows hierarchical relationships between objects\n"
     ]
    }
   ],
   "source": [
    "# 39) What is a dendogram?\n",
    "# None of the above\n",
    "# Shows hierarchical relationships between objects\n",
    "# Shows inter-cluster variance in hierarchical clustering\n",
    "# Shows intra-cluster variance in hierarchical clustering\n",
    "\n",
    "print(\"Shows hierarchical relationships between objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both 1 and 2\n"
     ]
    }
   ],
   "source": [
    "# 40) What is agglomerative hierarchical clustering?\n",
    "# Both 1 and 2\n",
    "# None of the above\n",
    "# Treats a single value as a cluster until one cluster is left\n",
    "# A bottom-up clustering approach\n",
    "\n",
    "print(\"Both 1 and 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardization helps in uniformity in the data\n"
     ]
    }
   ],
   "source": [
    "# 41) Why do we standardize the data before dimensionality reduction?\n",
    "# Standardization helps in uniformity in the data\n",
    "# None of the options are correct\n",
    "# Standardization helps in data imputation\n",
    "# Standardization is not required before dimensionality reduction\n",
    "\n",
    "print(\"Standardization helps in uniformity in the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The major component explains the maximum information of the data\n"
     ]
    }
   ],
   "source": [
    "# 42) What does the major component in PCA tell us?\n",
    "# The major component explains the accuracy of the model\n",
    "# The major component explains the number of features\n",
    "# None of the options are correct\n",
    "# The major component explains the maximum information of the data\n",
    "\n",
    "print(\"The major component explains the maximum information of the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Explained Variance Ratio\n"
     ]
    }
   ],
   "source": [
    "# 43) How do you decide the number of components in PCA?\n",
    "# Intra-cluster Variance\n",
    "# Cumulative Explained Variance Ratio\n",
    "# Inter-cluster Variance\n",
    "# None of the options are correct\n",
    "\n",
    "print(\"Cumulative Explained Variance Ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the options are correct\n"
     ]
    }
   ],
   "source": [
    "# 44) What inferences can be drawn if all the eigenvalues are equal.\n",
    "# No principal components will have any significance\n",
    "# All the options are correct\n",
    "# PCA will fail to reduce dimensions\n",
    "# All principal components will be equal\n",
    "\n",
    "print(\"All the options are correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalies show an increased loss while inverse transformation\n"
     ]
    }
   ],
   "source": [
    "# 45) How do you use PCA to detect anomalies?\n",
    "# Anomalies show an increased loss while inverse transformation\n",
    "# None of the above\n",
    "# Anomaly detection cannot be done using PCA\n",
    "# Anomalies show a reduced loss while inverse transformation\n",
    "\n",
    "print(\"Anomalies show an increased loss while inverse transformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Between class variance is maximized relative to within class variance\n"
     ]
    }
   ],
   "source": [
    "# 46) How does LDA calculate its maximum separation?\n",
    "# LDA calculates maximum separation using ADFuller Test\n",
    "# LDA does not calculate maximum separation\n",
    "# Between class variance is maximized relative to within class variance\n",
    "# None of the options are correct\n",
    "\n",
    "print(\"Between class variance is maximized relative to within class variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA is unsupervised and LDA is supervised\n"
     ]
    }
   ],
   "source": [
    "# 47) What is the difference between PCA and LDA?\n",
    "# PCA is unsupervised and LDA is supervised\n",
    "# PCA is supervised and LDA is unsupervised\n",
    "# None of the options are correct\n",
    "# PCA calculates maximum class separation, LDA calculates minimum class separation\n",
    "\n",
    "print(\"PCA is unsupervised and LDA is supervised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised\n"
     ]
    }
   ],
   "source": [
    "# 48) Is LDA supervised or unsupervised?\n",
    "# Supervised\n",
    "# Unsupervised\n",
    "\n",
    "print(\"Supervised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only in problems with target as categorical variable\n"
     ]
    }
   ],
   "source": [
    "# 49) Can LDA be used as a classifier?\n",
    "# Cannot be used a classifier\n",
    "# Only in problems with target as continuous variable\n",
    "# None of the options are correct\n",
    "# Only in problems with target as categorical variable\n",
    "\n",
    "print(\"Only in problems with target as categorical variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE\n"
     ]
    }
   ],
   "source": [
    "# 50) Linear Discriminant Analysis can be used for clustering\n",
    "# False\n",
    "# True\n",
    "\n",
    "print(\"TRUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the options are correct\n"
     ]
    }
   ],
   "source": [
    "# 51) If the mean squared error of a model is given by zero, what can you say about the model?\n",
    "# All the options are correct\n",
    "# The model is perfect\n",
    "# R2 score will be 1 for the model\n",
    "# The model shows absolutely no error in predictions\n",
    "\n",
    "print(\"All the options are correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE ACCURACY OF THE MODEL IS NOT ACCEPTABLE WITH POOR EFFICIENCY\n"
     ]
    }
   ],
   "source": [
    "# 52) If the mean absolute percentage error of a model is given by 28, what can you say about the model?\n",
    "# The accuracy of the model is not acceptable with low efficiency\n",
    "# The accuracy of the model is not acceptable with poor efficiency\n",
    "# The accuracy of the model is acceptable with high efficiency\n",
    "# The accuracy of the model is acceptable with moderate efficiency\n",
    "\n",
    "print(\"THE ACCURACY OF THE MODEL IS NOT ACCEPTABLE WITH POOR EFFICIENCY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      "[[12  8]\n",
      " [ 4 41]]\n",
      "0.75\n",
      "correct ans:0.75\n"
     ]
    }
   ],
   "source": [
    "# 53) For the given confusion matrix, if the truth value corresponds with 0, what is the precision of the model when the target is true.\n",
    "# confusion matrix\n",
    "# 0.87\n",
    "# 0.84\n",
    "# 0.82\n",
    "# 0.75\n",
    "import numpy as np\n",
    "\n",
    "#precision = true positives / (true positives + false positives)\n",
    "cm = np.array([[12,8],[4,41]])\n",
    "print(f'confusion matrix: \\n{cm}')\n",
    "precision = 12/(12+4)\n",
    "print(precision)\n",
    "print(\"correct ans:0.75\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "correct answer: 0.60\n"
     ]
    }
   ],
   "source": [
    "# 54) For the given confusion matrix, if the truth value corresponds with 0, what is the recall of the model when the target is true.\n",
    "# confusion matrix\n",
    "# 0.87\n",
    "# 0.67\n",
    "# 0.60\n",
    "# 0.91\n",
    "\n",
    "#recall = true positives / (true positives + false negatives)\n",
    "\n",
    "recall = 12/(12+8)\n",
    "print(recall)\n",
    "print(\"correct answer: 0.60\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.67\n",
      "correct answer: 0.67\n"
     ]
    }
   ],
   "source": [
    "# 55) For the given confusion matrix, if the truth value corresponds with 0, what is the f1-score of the model when the target is true.\n",
    "# confusion matrix\n",
    "# 0.84\n",
    "# 0.75\n",
    "# 0.87\n",
    "# 0.67\n",
    "\n",
    "#f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "fi_score = 2 * (precision * recall)/(precision + recall)\n",
    "print(f'f1_score: {fi_score:.2f}')\n",
    "print(\"correct answer: 0.67\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurcy: 0.82\n"
     ]
    }
   ],
   "source": [
    "# 56) For the given confusion matrix, what is the accuracy of the model?confusion matrix\n",
    "# 0.82\n",
    "# 0.84\n",
    "# 1.0\n",
    "# 0.75\n",
    "\n",
    "accuracy = (12+41)/(12+41+4+8)\n",
    "print(f'accurcy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificity : 0.91\n",
      "correct answer: 0.91\n"
     ]
    }
   ],
   "source": [
    "# 57) For the given confusion matrix, if the truth value corresponds with 0, what is the specificity of the model when the target is true.\n",
    "# confusion matrix\n",
    "# 0.91\n",
    "# 0.84\n",
    "# None of the options are correct\n",
    "# 0.60\n",
    "\n",
    "#specificity = true negatives / (true negatives + false positives)\n",
    "\n",
    "specificity = 41/(41+4)\n",
    "print(f'specificity : {specificity:.2f}')\n",
    "print(\"correct answer: 0.91\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity : 0.60\n",
      "0.60\n"
     ]
    }
   ],
   "source": [
    "# 58) For the given confusion matrix, if the truth value corresponds with 0, what is the sensitivity of the model when the target is true.\n",
    "# confusion matrix\n",
    "# 0.91\n",
    "# None of the options are correct\n",
    "# 0.60\n",
    "# 0.84\n",
    "\n",
    "#sensitivity = true positives / (true positives + false negatives)\n",
    "\n",
    "sensitivity = 12/(12+8)\n",
    "print(f'sensitivity : {sensitivity:.2f}')\n",
    "\n",
    "print(\"0.60\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All options are correct\n"
     ]
    }
   ],
   "source": [
    "# 59) If the r2_score of the model is given by 1, what can you say about the model?\n",
    "# 100% of the variance of the dependent variable is explained by independent variable\n",
    "# All options are correct\n",
    "# Mean Squared error is Zero\n",
    "# The model is a perfect fit\n",
    "\n",
    "print(\"All options are correct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of all absolute errors is zero\n"
     ]
    }
   ],
   "source": [
    "# 60) If the mean absolute error of a model is given by zero, what can you say about the model?\n",
    "# The model is not a perfect fit\n",
    "# R2 score is 0\n",
    "# The mean of all absolute errors is zero\n",
    "# None of the options are correct\n",
    "\n",
    "print(\"The mean of all absolute errors is zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6.86x",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

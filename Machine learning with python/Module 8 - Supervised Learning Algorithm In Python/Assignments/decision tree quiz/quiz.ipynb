{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                   Name Type 1  Type 2  Total  HP  Attack  Defense  \\\n",
       "0  1              Bulbasaur  Grass  Poison    318  45      49       49   \n",
       "1  2                Ivysaur  Grass  Poison    405  60      62       63   \n",
       "2  3               Venusaur  Grass  Poison    525  80      82       83   \n",
       "3  3  VenusaurMega Venusaur  Grass  Poison    625  80     100      123   \n",
       "4  4             Charmander   Fire     NaN    309  39      52       43   \n",
       "\n",
       "   Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0       65       65     45           1      False  \n",
       "1       80       80     60           1      False  \n",
       "2      100      100     80           1      False  \n",
       "3      122      120     80           1      False  \n",
       "4       60       50     65           1      False  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Pokemon.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. How many pokemon are from the 5th generation?\n",
    "# a. 178\n",
    "# b. 165\n",
    "# c. 150\n",
    "# d. 170\n",
    "\n",
    "df[df['Generation'] == 5].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. How many pokemon have the highest defense score?\n",
    "# a. 10\n",
    "# b. 7\n",
    "# c. 3\n",
    "# d. 2\n",
    "\n",
    "\n",
    "df[df['Defense']==df['Defense'].max()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d. Fill up the null values with None.\n",
      "\n",
      "\n",
      "#               0\n",
      "Name            0\n",
      "Type 1          0\n",
      "Type 2        386\n",
      "Total           0\n",
      "HP              0\n",
      "Attack          0\n",
      "Defense         0\n",
      "Sp. Atk         0\n",
      "Sp. Def         0\n",
      "Speed           0\n",
      "Generation      0\n",
      "Legendary       0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   #           800 non-null    int64 \n",
      " 1   Name        800 non-null    object\n",
      " 2   Type 1      800 non-null    object\n",
      " 3   Type 2      414 non-null    object\n",
      " 4   Total       800 non-null    int64 \n",
      " 5   HP          800 non-null    int64 \n",
      " 6   Attack      800 non-null    int64 \n",
      " 7   Defense     800 non-null    int64 \n",
      " 8   Sp. Atk     800 non-null    int64 \n",
      " 9   Sp. Def     800 non-null    int64 \n",
      " 10  Speed       800 non-null    int64 \n",
      " 11  Generation  800 non-null    int64 \n",
      " 12  Legendary   800 non-null    bool  \n",
      "dtypes: bool(1), int64(9), object(3)\n",
      "memory usage: 75.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 3. How you will be handling missing values in this dataset:\n",
    "# a. Fill up the null values with the median.\n",
    "# b. Fill up the null values with standard deviation.\n",
    "# c. Fill up the null values with the mean.\n",
    "# d. Fill up the null values with None.\n",
    "\n",
    "print('d. Fill up the null values with None.')\n",
    "print('\\n')\n",
    "print(df.isnull().sum())\n",
    "print('\\n')\n",
    "print(df.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arvin\\AppData\\Local\\Temp\\ipykernel_22264\\3632920018.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df.corr()['Generation'].sort_values(ascending=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Speed        -0.023121\n",
       "Sp. Def       0.028486\n",
       "Sp. Atk       0.036437\n",
       "Defense       0.042419\n",
       "Total         0.048384\n",
       "Attack        0.051451\n",
       "HP            0.058683\n",
       "Legendary     0.079794\n",
       "#             0.982516\n",
       "Generation    1.000000\n",
       "Name: Generation, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['Generation'].sort_values(ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both Attack and Speed\n"
     ]
    }
   ],
   "source": [
    "# 4. Which columns are not having any kind of relationship with the generation\n",
    "# column?\n",
    "# a. Attack\n",
    "# b. Speed\n",
    "# c. Both of the above\n",
    "# d. None of the above\n",
    "\n",
    "print('Both Attack and Speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d. Random Forest Model\n"
     ]
    }
   ],
   "source": [
    "# 5. Which of the following model is the best fit for predicting the legendary of the\n",
    "# pokemon based on the below parameters:\n",
    "# 1. Handle the missing values.\n",
    "# 2. Split the dataset into a 70:30 ratio with random_state as 1.\n",
    "# a. Linear Regression\n",
    "# b. Logistic Regression\n",
    "# c. Decision Tree Model\n",
    "# d. Random Forest Model\n",
    "\n",
    "print('d. Random Forest Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for the negative class (target is False): 0.96\n",
      "a. 0.90 to 0.1\n"
     ]
    }
   ],
   "source": [
    "# 6. What is the precision of the Decision Tree model when the target is False?\n",
    "# a. 0.90 to 0.1\n",
    "# b. 0.80 to 0.90\n",
    "# c. 1.0 to 2.0\n",
    "# d. 0.50 to 0.60\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, confusion_matrix\n",
    "\n",
    "df.rename(columns={'#':'ID'},inplace=True)\n",
    "\n",
    "# Handle missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "df['Type 1'] = label_encoder.fit_transform(df['Type 1'])\n",
    "df['Type 2'] = label_encoder.fit_transform(df['Type 2'])\n",
    "\n",
    "\n",
    "# Split the dataset\n",
    "X = df.drop(columns=['ID', 'Name', 'Legendary'])\n",
    "y = df['Legendary']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Build and fit the Decision Tree model\n",
    "model = DecisionTreeClassifier(random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate precision for the negative class (target is False)\n",
    "precision = precision_score(y_test, y_pred, pos_label=False)\n",
    "print(f\"Precision for the negative class (target is False): {precision:.2f}\")\n",
    "print('a. 0.90 to 0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not Legendary       0.96      0.96      0.96       114\n",
      "    Legendary       0.64      0.64      0.64        11\n",
      "\n",
      "     accuracy                           0.94       125\n",
      "    macro avg       0.80      0.80      0.80       125\n",
      " weighted avg       0.94      0.94      0.94       125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate classification report\n",
    "class_report = classification_report(y_test, y_pred, target_names=['Not Legendary', 'Legendary'])\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not Legendary       0.96      0.96      0.96       114\n",
      "    Legendary       0.64      0.64      0.64        11\n",
      "\n",
      "     accuracy                           0.94       125\n",
      "    macro avg       0.80      0.80      0.80       125\n",
      " weighted avg       0.94      0.94      0.94       125\n",
      "\n",
      "0.50 to 0.60\n"
     ]
    }
   ],
   "source": [
    "# 7. What is the sensitivity of the above model when the target is True?\n",
    "# a. 0.90 to 1.0\n",
    "# b. 0.50 to 0.60\n",
    "# c. 0.60 to 0.70\n",
    "# d. 0.30 to 0.40\n",
    "\n",
    "print(class_report)\n",
    "\n",
    "# when target is false:\n",
    "# specificity = true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "print('0.50 to 0.60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a. Between 15 to 20\n",
      "Confusion Matrix:\n",
      "[[110   4]\n",
      " [  4   7]]\n",
      "Correctly Classified Data Count: 8\n"
     ]
    }
   ],
   "source": [
    "# 8. How much correctly classified data has been retrieved from the above model?\n",
    "# a. Between 15 to 20\n",
    "# b. Between 7 to 10\n",
    "# c. Between 30 to 45\n",
    "# d. Between 50 to 70\n",
    "\n",
    "print('a. Between 15 to 20')\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate the count of correctly classified data\n",
    "correctly_classified_count = conf_matrix[1, 0] + conf_matrix[0, 1]\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(f\"Correctly Classified Data Count: {correctly_classified_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a. Balance the dataset prior to fitting\n"
     ]
    }
   ],
   "source": [
    "# 9. Decision tree models might create some biased trees if some classes\n",
    "# dominate. From the below options which action is best to take so that it\n",
    "# won't create biased trees:\n",
    "# a. balance the dataset prior to fitting\n",
    "# b. imbalance the dataset prior to fitting\n",
    "# c. balance the dataset after fitting\n",
    "# d. None of the above\n",
    "\n",
    "print(\"a. Balance the dataset prior to fitting\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b. Decision Tree\n"
     ]
    }
   ],
   "source": [
    "# 10.Suppose, you have to work with an ML problem, where you have to predict\n",
    "# the number of oxygen tanks needed to be shipped from Indonesia. Which\n",
    "# of the following ML algorithm you will choose:\n",
    "# a. Logistic regression\n",
    "# b. Decision Tree\n",
    "# c. Both of the above\n",
    "\n",
    "print('b. Decision Tree')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d. All of the above\n"
     ]
    }
   ],
   "source": [
    "# 11.Which of the following is true for the Decision Tree?\n",
    "# a. The model can able to generate understandable rules\n",
    "# b. The model can able to handle both continuous and categorical\n",
    "# variables\n",
    "# c. It can able to perform classification without requiring much computation\n",
    "# d. All of the above\n",
    "\n",
    "print(\"d. All of the above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a. True\n"
     ]
    }
   ],
   "source": [
    "# 12.The total gain is computed by adding the expected value of each\n",
    "# outcome and deducting the costs associated with the decision.\n",
    "# a. True\n",
    "# b. False\n",
    "\n",
    "print('a. True')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c. Both of above\n"
     ]
    }
   ],
   "source": [
    "# 13.How we can avoid the overfitting in Decision Tree\n",
    "# a. Stopping the Tree Growth\n",
    "# b. Pruning the Full Grown Tree\n",
    "# c. Both of above\n",
    "# d. None of the Above\n",
    "\n",
    "print('c. Both of above')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6.86x",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
